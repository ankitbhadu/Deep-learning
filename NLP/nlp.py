# -*- coding: utf-8 -*-
"""nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qqszgk6HiLi5nu_nrvWkFn4Fbvz08GJC
"""

from fastai import *
import matplotlib.pyplot as plt
from fastai.text import *
import pandas as pd
from sklearn.model_selection import train_test_split

#getting dataset stored in github repo 
! git clone https://github.com/ankitbhadu/deep-learning.git

!cd /content/deep-learning/NLP
!ls

# we'll use only headline and short description to classify the news articles
df=pd.read_json(r'/content/deep-learning/NLP/news_train.json',lines=True)

df1 = df[['category','headline','short_description']]

df1["headline"] = df1["headline"].astype(str) +". "+ df1["short_description"]

df2=df1[['category','headline']]

df2['headline'][0]

df2.head()


#splitting dataset into training and validation sets
df_trn, df_val = train_test_split(df2, stratify = df2['category'], test_size = 0.1, random_state = 12)

df_trn.shape, df_val.shape


data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = "",)

data_clas = TextClasDataBunch.from_df(path = "", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=128,)

#using wikitext pre trained model to create a lml
learn = language_model_learner(data_lm, pretrained=True, drop_mult=0.7,arch=AWD_LSTM,)

learn.lr_find()

learn.recorder.plot()

learn.fit_one_cycle(8, 2e-2, moms=(0.8,0.7))

learn.save('first')

learn.fit_one_cycle(8, 2e-2, moms=(0.8,0.7))

learn.save('second')

learn.fit_one_cycle(8, max_lr=slice(1e-4,1e-2),)

learn.save('third')

learn.unfreeze()
learn.fit_one_cycle(5, max_lr=slice(1e-4,1e-2))

learn.fit_one_cycle(1, max_lr=slice(1e-4,1e-2))

learn.fit_one_cycle(5, max_lr=slice(1e-4,1e-2))

# saving only the part we will need to classify data rather than saving the whole model
learn.save_encoder('ft_enc')

#creating a RNN model for text classification
learn = text_classifier_learner(data_clas, drop_mult=0.7,arch= AWD_LSTM)

learn.load_encoder('ft_enc')

learn.lr_find()

learn.recorder.plot()
#fine tuning the model to increase accuracy
learn.fit_one_cycle(8,max_lr=slice(1e-4,3e-2) , moms=(0.8,0.7))

learn.save('fourth')

learn.load('fourth')

learn.lr_find()

learn.recorder.plot()

learn.save('fifth')

learn.fit_one_cycle(8,max_lr=slice(1e-5,3e-4) )



learn.save('sixth')

learn.lr_find()

learn.recorder.plot()

learn.unfreeze()
learn.fit_one_cycle(8, max_lr=slice(1e-6,5e-3))

learn.save('seventh')

learn.load('seventh')



dft=pd.read_json(r'/content/deep-learning/NLP/news_test.json',lines=True)

dft.head()

dft1 = dft[['headline','short_description']]

dft1.head()

dft1["headline"] = dft1["headline"].astype(str) +". "+ dft1["short_description"]

dft2=dft1[['headline']]

dft2.head()

learn.export()

test = TextList.from_df(dft2,path="")

data_clas.add_test(test)

learn = load_learner('/content/', test=test,)

preds,y = learn.get_preds(ds_type=DatasetType.Test,ordered=True,)

preds[:2]





labelled_preds

#replacing int categories by their corresponding name labels
labelled_preds_name = [data_clas.classes[pred] for pred in labelled_preds]

labelled_preds_name

data_clas.classes

dft=pd.read_json(r'/content/deep-learning/NLP/news_test.json',lines=True)

dft1=dft[['headline','short_description']]

dft1["headline"] = dft1["headline"].astype(str) +". "+ dft1["short_description"]

labelled_preds

dft2.head()

fnames = [f for f in dft2['headline']]

fnames[:2]

df = pd.DataFrame({'text':fnames, 'labels':labelled_preds_name}, columns=['text', 'labels'])

df.head()

# exporting the required csv file
export_csv = df.to_csv (r'/content/export_dataframe.csv')

df1=df['labels']

df1.head()







